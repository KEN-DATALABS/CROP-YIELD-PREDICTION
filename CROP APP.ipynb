{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "589fb5dc-2213-474b-abef-70ae0006c49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-13 12:42:36.080 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\user\\3D Objects\\ANACONDA\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-07-13 12:42:36.213 Session state does not function when running a script without `streamlit run`\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Set up Streamlit layout to use full screen width\n",
    "st.set_page_config(layout=\"wide\")\n",
    "\n",
    "# App Title\n",
    "st.title(\"CROP YIELD PREDICTION APP\")\n",
    "\n",
    "# Introductory markdown explaining the app's purpose\n",
    "st.markdown(\"\"\"\n",
    "Welcome to the Crop Yield Prediction App!  \n",
    "This tool guides you from dataset upload to model prediction through interactive analysis, cleaning, and visualization.  \n",
    "Upload your dataset or use a sample to begin your journey!\n",
    "\"\"\")\n",
    "\n",
    "# Sidebar navigation options for different stages of the app\n",
    "st.sidebar.title(\"Navigation\")\n",
    "options = st.sidebar.radio(\"Select Step:\", \n",
    "                          [\"Upload Data\", \"Data Cleaning\", \n",
    "                           \"Visualization\", \"Preprocessing\",\n",
    "                           \"Prediction\", \"Insights\"])\n",
    "\n",
    "# Initialize Streamlit session state variables to persist data across steps\n",
    "for key in ['df', 'cleaned_df', 'target', 'model_type', 'model', 'report']:\n",
    "    if key not in st.session_state:\n",
    "        st.session_state[key] = None\n",
    "\n",
    "# Define the required columns expected in the uploaded dataset\n",
    "expected_columns = [\"Area\", \"Item\", \"Year\", \"hg/ha_yield\", \n",
    "                    \"average_rain_fall_mm_per_year\", \"pesticides_tonnes\", \n",
    "                    \"avg_temp\"]\n",
    "\n",
    "# Step 1: Upload or Load Dataset\n",
    "if options == \"Upload Data\":\n",
    "    st.header(\"Upload or Select Dataset\")\n",
    "\n",
    "    df = None  # Initialize an empty DataFrame variable to avoid reference issues\n",
    "\n",
    "    # Provide user with two options: upload own dataset or use a default one\n",
    "    data_source = st.radio(\"Choose a data source:\", ['Upload your dataset', 'Use default dataset'])\n",
    "\n",
    "    # CASE 1: Uploading a custom dataset\n",
    "    if data_source == 'Upload your dataset':\n",
    "        uploaded_file = st.file_uploader(\"Upload CSV or Excel file\", type=[\"csv\", \"xlsx\"])\n",
    "\n",
    "        # Process uploaded file if provided\n",
    "        if uploaded_file:\n",
    "            try:\n",
    "                # Read based on file type\n",
    "                if uploaded_file.name.endswith(\".csv\"):\n",
    "                    df = pd.read_csv(uploaded_file)\n",
    "                else:\n",
    "                    df = pd.read_excel(uploaded_file)\n",
    "\n",
    "                st.success(\"File uploaded and read successfully.\")\n",
    "            except Exception as e:\n",
    "                st.error(f\"Error reading file: {e}\")\n",
    "                df = None  # Prevent later usage if file fails\n",
    "\n",
    "    # CASE 2: Load default dataset from project directory\n",
    "    else:\n",
    "        try:\n",
    "            df = pd.read_csv(\"yield_df.csv\")  # Ensure this file is available in the working folder\n",
    "            st.success(\"Default dataset loaded successfully.\")\n",
    "        except FileNotFoundError:\n",
    "            st.error(\"Default dataset not found in the directory.\")\n",
    "            df = None\n",
    "\n",
    "        # Provide sample structure for download to guide new users\n",
    "        st.markdown(\"Don't have a dataset? [Download Example CSV](https://raw.githubusercontent.com/datasciencedojo/datasets/master/Agricultural%20Production.csv)\")\n",
    "        \n",
    "        # Provide downloadable blank template CSV with only column headers\n",
    "        st.download_button(\n",
    "            label=\"Download Example Dataset\",\n",
    "            data=pd.DataFrame(columns=expected_columns).to_csv(index=False),\n",
    "            file_name='example_crop_data.csv',\n",
    "            mime='text/csv'\n",
    "        )\n",
    "\n",
    "    # Proceed with data inspection if a dataset is successfully loaded\n",
    "    if df is not None:\n",
    "        # Check for missing expected columns in uploaded/default data\n",
    "        missing_columns = [col for col in expected_columns if col not in df.columns]\n",
    "\n",
    "        if missing_columns:\n",
    "            # Display error if required columns are missing\n",
    "            st.error(\"Dataset is missing the following required columns:\")\n",
    "            st.write(missing_columns)\n",
    "        else:\n",
    "            # Check and drop any extra columns not needed\n",
    "            extra_columns = [col for col in df.columns if col not in expected_columns]\n",
    "            if extra_columns:\n",
    "                df = df[expected_columns]  # Keep only necessary columns\n",
    "                st.warning(f\"Extra columns dropped: {extra_columns}\")\n",
    "\n",
    "            # Store valid DataFrame in session state for reuse in other steps\n",
    "            st.session_state.df = df\n",
    "\n",
    "            # Display feedback and data summaries\n",
    "            st.success(\"Dataset is valid and ready for analysis!\")\n",
    "\n",
    "            # Data preview (first 5 rows)\n",
    "            st.subheader(\"Data Preview\")\n",
    "            st.dataframe(df.head())\n",
    "\n",
    "            # Show data types of all columns\n",
    "            st.subheader(\"Data Types\")\n",
    "            st.dataframe(pd.DataFrame(df.dtypes, columns=[\"Data Type\"]))\n",
    "\n",
    "            # Basic info: number of rows and columns\n",
    "            st.subheader(\"Dataset Overview\")\n",
    "            st.write(f\"Rows: {df.shape[0]} | Columns: {df.shape[1]}\")\n",
    "\n",
    "            # Descriptive statistics for all columns\n",
    "            st.subheader(\"Descriptive Statistics\")\n",
    "            st.dataframe(df.describe(include='all'))\n",
    "\n",
    "            # Section: Missing Values Summary\n",
    "            st.subheader(\"Missing Values\")\n",
    "            # Define common missing value representations not detected by default (e.g., 'NA', '-', '', etc.)\n",
    "            missing_values = ['NA', 'na', 'n/a', 'N/a', '', 'null', '-']\n",
    "            # Replace all custom missing value indicators with np.nan\n",
    "            for column in df.columns:\n",
    "                df[column] = df[column].replace(missing_values, np.nan)\n",
    "            # Create a summary DataFrame of missing values\n",
    "            missing_df = pd.DataFrame(df.isna().sum(), columns=['Missing Values'])\n",
    "            missing_df[\"Percentage (%)\"] = (missing_df['Missing Values'] / len(df)) * 100\n",
    "            missing_df = missing_df[missing_df['Missing Values'] > 0]  # Show only columns with missing data\n",
    "            # Display the missing values summary table in the Streamlit app\n",
    "            st.dataframe(missing_df.style.format({\"Percentage (%)\": \"{:.2f}\"}))\n",
    "\n",
    "\n",
    "            # Count and show number of duplicate rows\n",
    "            st.subheader(\"Duplicate Rows\")\n",
    "            st.write(f\"Number of duplicate rows: {df.duplicated().sum()}\")\n",
    "            \n",
    "# Step 2: Data Cleaning\n",
    "elif options == \"Data Cleaning\":\n",
    "    st.header(\"Data Cleaning\")\n",
    "\n",
    "    # Ensure a dataset is loaded before proceeding\n",
    "    if st.session_state.df is not None:\n",
    "        df = st.session_state.df\n",
    "\n",
    "        st.subheader(\"Data Issues Detected\")\n",
    "\n",
    "        issues = []  # List to hold all detected data quality issues\n",
    "\n",
    "        # 1. Check for Missing Values\n",
    "        total_missing = df.isna().sum().sum()\n",
    "        if total_missing > 0:\n",
    "            issues.append(f\"Missing values detected: {total_missing} total\")    \n",
    "\n",
    "        # 2. Check for Duplicate Rows\n",
    "        duplicates = df.duplicated().sum()\n",
    "        if duplicates > 0:\n",
    "            issues.append(f\"Duplicate rows detected: {duplicates}\")\n",
    "\n",
    "        # 3. Outlier Detection using IQR method\n",
    "        numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "        outlier_cols = []  # Keep track of columns that contain outliers\n",
    "\n",
    "        for col in numeric_cols:\n",
    "            Q1 = df[col].quantile(0.25)\n",
    "            Q3 = df[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            outliers = df[(df[col] < (Q1 - 1.5 * IQR)) | (df[col] > (Q3 + 1.5 * IQR))]\n",
    "\n",
    "            if not outliers.empty:\n",
    "                issues.append(f\"Potential outliers detected in '{col}'\")\n",
    "                outlier_cols.append(col)\n",
    "\n",
    "        # Visualize detected outliers using boxplots\n",
    "        if outlier_cols:\n",
    "            st.write(\"The following columns have potential outliers:\")\n",
    "            for col in outlier_cols:\n",
    "                fig, ax = plt.subplots(figsize=(5, 3))\n",
    "                sns.boxplot(df[col], color='skyblue', ax=ax)\n",
    "                ax.set_title(f'Outliers in {col}', fontsize=12)\n",
    "                st.pyplot(fig)\n",
    "\n",
    "        # 4. Check for numeric data stored as text\n",
    "        for col in df.select_dtypes(include='object').columns:\n",
    "            try:\n",
    "                pd.to_numeric(df[col])  # Attempt conversion\n",
    "                issues.append(f\"Column '{col}' contains numeric data stored as text\")\n",
    "            except:\n",
    "                pass  # If conversion fails, ignore\n",
    "\n",
    "        # Display detected issues\n",
    "        if issues:\n",
    "            st.warning(\"The following data issues were found:\")\n",
    "            for issue in issues:\n",
    "                st.markdown(f\"- {issue}\")\n",
    "        else:\n",
    "            st.success(\"No major data issues detected!\")\n",
    "\n",
    "\n",
    "        # Data Cleaning Interface\n",
    "        st.subheader(\"Data Cleaning Options\")\n",
    "        \n",
    "        # Let user choose multiple cleaning actions\n",
    "        cleaning_options = st.multiselect(\n",
    "            \"Select cleaning actions to apply:\",\n",
    "            [\n",
    "                \"Fixing Column Types\",\n",
    "                \"Rename 'Items' to 'Crop'\",\n",
    "                \"Remove duplicate rows\",\n",
    "                \"Fill missing values (numeric)\",\n",
    "                \"Fill missing values (categorical)\",\n",
    "                \"Remove rows with missing values\",\n",
    "                \"Remove columns with high missing values (>30%)\",\n",
    "                \"Convert text to numeric where possible\",\n",
    "                \"Remove outliers (for numeric columns)\",\n",
    "                \"Standardize column names\"\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Button to apply selected cleaning steps\n",
    "        if st.button(\"Clean Data\"):\n",
    "            cleaned_df = df.copy()  # Work on a copy of the dataset\n",
    "\n",
    "            if \"Fixing Column Types\" in cleaning_options:\n",
    "                # Fix incompatible column types before using st.dataframe()\n",
    "                for col in df.columns:\n",
    "                    if df[col].dtype == 'object':\n",
    "                        # Attempt to convert if values are numeric-like\n",
    "                        try:\n",
    "                            df[col] = pd.to_numeric(df[col])\n",
    "                        except:\n",
    "                            df[col] = df[col].astype(str)\n",
    "\n",
    "            # Change Items to Crop\n",
    "            if \"Rename 'Items' to 'Crop'\" in cleaning_options:\n",
    "                cleaned_df.rename(columns={'Item':'Crop'}, inplace=True)\n",
    "            \n",
    "            # Remove duplicates\n",
    "            if \"Remove duplicate rows\" in cleaning_options:\n",
    "                cleaned_df = cleaned_df.drop_duplicates()\n",
    "\n",
    "            # Fill missing numeric values with column mean\n",
    "            if \"Fill missing values (numeric)\" in cleaning_options:\n",
    "                from sklearn.impute import SimpleImputer\n",
    "                numeric_cols = cleaned_df.select_dtypes(include=['int64', 'float64']).columns\n",
    "                imputer = SimpleImputer(strategy='mean')\n",
    "                cleaned_df[numeric_cols] = imputer.fit_transform(cleaned_df[numeric_cols])\n",
    "\n",
    "            # Fill missing categorical values with mode\n",
    "            if \"Fill missing values (categorical)\" in cleaning_options:\n",
    "                cat_cols = cleaned_df.select_dtypes(include=['object']).columns\n",
    "                for col in cat_cols:\n",
    "                    if cleaned_df[col].isnull().sum() > 0:\n",
    "                        cleaned_df[col].fillna(cleaned_df[col].mode()[0], inplace=True)\n",
    "\n",
    "            # Drop any row that still contains missing values\n",
    "            if \"Remove rows with missing values\" in cleaning_options:\n",
    "                cleaned_df.dropna(inplace=True)\n",
    "\n",
    "            # Drop columns where more than 30% of values are missing\n",
    "            if \"Remove columns with high missing values (>30%)\" in cleaning_options:\n",
    "                threshold = len(cleaned_df) * 0.3\n",
    "                cleaned_df.dropna(axis=1, thresh=threshold, inplace=True)\n",
    "\n",
    "            # Convert any column with numeric text to actual numeric type\n",
    "            if \"Convert text to numeric where possible\" in cleaning_options:\n",
    "                for col in cleaned_df.columns:\n",
    "                    if cleaned_df[col].dtype == 'object':\n",
    "                        try:\n",
    "                            cleaned_df[col] = pd.to_numeric(cleaned_df[col])\n",
    "                        except:\n",
    "                            pass  # Ignore conversion errors\n",
    "\n",
    "            # Remove outliers using the 3-standard-deviation rule\n",
    "            if \"Remove outliers (for numeric columns)\" in cleaning_options:\n",
    "                for col in cleaned_df.select_dtypes(include=['int64', 'float64']).columns:\n",
    "                    mean = cleaned_df[col].mean()\n",
    "                    std = cleaned_df[col].std()\n",
    "                    cleaned_df = cleaned_df[\n",
    "                        (cleaned_df[col] <= mean + 3 * std) &\n",
    "                        (cleaned_df[col] >= mean - 3 * std)\n",
    "                    ]\n",
    "\n",
    "            # Rename all columns to lowercase with underscores (standard format)\n",
    "            if \"Standardize column names\" in cleaning_options:\n",
    "                cleaned_df.columns = cleaned_df.columns.str.strip().str.replace(\" \", \"_\").str.capitalize()\n",
    "                \n",
    "            # Save cleaned data to session state for reuse in later steps\n",
    "            st.session_state.cleaned_df = cleaned_df\n",
    "\n",
    "            # Display cleaning result\n",
    "            st.success(\"Data cleaning completed successfully!\")\n",
    "\n",
    "            # Preview cleaned dataset\n",
    "            st.subheader(\"Cleaned Data Preview\")\n",
    "            st.dataframe(cleaned_df.head())\n",
    "\n",
    "            # Cleaning summary statistics\n",
    "            st.subheader(\"Cleaning Summary\")\n",
    "            st.write(f\"Original shape: {df.shape}\")\n",
    "            st.write(f\"New shape: {cleaned_df.shape}\")\n",
    "            st.write(f\"Rows removed: {df.shape[0] - cleaned_df.shape[0]}\")\n",
    "            st.write(f\"Columns removed: {df.shape[1] - cleaned_df.shape[1]}\")\n",
    "\n",
    "    else:\n",
    "        # Message shown if user tries to access this step before uploading data\n",
    "        st.warning(\"Please upload a dataset first in the 'Upload Data' section.\")\n",
    "\n",
    "elif options == \"Data Cleaning\" and st.session_state.df is None:\n",
    "    st.warning(\"Please upload a dataset first in the 'Upload Data' section.\")\n",
    "    \n",
    "# STEP 3: Data Visualization\n",
    "elif options == \"Visualization\":\n",
    "    st.header(\"Data Visualization\")\n",
    "\n",
    "    # Ensure dataframe exista in session state\n",
    "    if st.session_state.cleaned_df is not None:\n",
    "        df = st.session_state.cleaned_df\n",
    "\n",
    "        if 'Crop' in df.columns:\n",
    "            st.subheader(\"Crop Distribution\")\n",
    "            # Count the occurences of each crop\n",
    "            crops=df['Crop'].value_counts()\n",
    "            # Create a figure\n",
    "            fig, ax = plt.subplots(figsize=(10, 10))\n",
    "            \n",
    "            # Slightly explode each slice for visual seperation\n",
    "            explode = [0.05] * len(crops)\n",
    "            # Plot the pie chart\n",
    "            ax.pie(crops, labels=crops.index,\n",
    "                   autopct='%1.1f%%',\n",
    "                   startangle=140,\n",
    "                   explode=explode, \n",
    "                   textprops={'fontsize': 20})\n",
    "            # Add title\n",
    "            ax.set_title('Crop Distribution (Pie)', fontsize=20)\n",
    "            # Display the chart in streamlit\n",
    "            def display_and_close(fig):\n",
    "                st.pyplot(fig)\n",
    "                plt.close(fig)\n",
    "            display_and_close(fig)\n",
    "\n",
    "            def style_axis_ticks(ax, axis='x', rotation=None, fontsize=12):\n",
    "                if axis == 'x':\n",
    "                    for tick in ax.get_xticklabels():\n",
    "                        if rotation is not None:\n",
    "                            tick.set_rotation(rotation)\n",
    "                        tick.set_fontsize(fontsize)\n",
    "                elif axis == 'y':\n",
    "                    for tick in ax.get_yticklabels():\n",
    "                        if rotation is not None:\n",
    "                            tick.set_rotation(rotation)\n",
    "                        tick.set_fontsize(fontsize)\n",
    "\n",
    "\n",
    "            # Bar Chart\n",
    "            # Convert to DataFrame for seaborn\n",
    "            crop_df = crops.reset_index()\n",
    "            crop_df.columns = ['Crop','Frequency']\n",
    "            # Create the bar plot\n",
    "            fig, ax = plt.subplots(figsize=(8, 8))\n",
    "            sns.barplot(\n",
    "                x='Crop',\n",
    "                y='Frequency',\n",
    "                data=crop_df,\n",
    "                palette='Spectral',\n",
    "                hue=crops.index)\n",
    "            # Style the plot\n",
    "            style_axis_ticks(ax, axis='x', rotation=80, fontsize=14)\n",
    "            style_axis_ticks(ax, axis='y', fontsize=14)\n",
    "            ax.set_xlabel('Crop', fontsize=16)\n",
    "            ax.set_ylabel('Frequency', fontsize=16)\n",
    "            ax.set_title('Crop Frequency Bar Chart', fontsize=17)\n",
    "            # Layout and display\n",
    "            plt.tight_layout()\n",
    "            display_and_close(fig)\n",
    "\n",
    "        st.subheader(\"Area Disribution\")\n",
    "        # Set figure size: wide vertically for long lists of areas\n",
    "        fig, ax = plt.subplots(figsize=(7, 13))\n",
    "        # Create a countplot showing the number of occurrences for each 'Area'\n",
    "        sns.countplot(data=df,y='Area',palette='husl',hue='Area')\n",
    "        # Adjust y-axis tick font size for better readability\n",
    "        style_axis_ticks(ax, axis='y', fontsize=8)\n",
    "        # Add labels and title for clarity\n",
    "        ax.set_xlabel('Frequency', fontsize=12)\n",
    "        ax.set_ylabel('Area', fontsize=12)\n",
    "        ax.set_title('Distribution of Records by Area', fontsize=14)\n",
    "        # Adjust layout to prevent overlapping\n",
    "        plt.tight_layout()\n",
    "        # Display the plot\n",
    "        display_and_close(fig)\n",
    "\n",
    "        # Top 20 Areas\n",
    "        st.subheader(\"Top 20 Areas by Frequency\")\n",
    "        # Get top 20 most frequent Areas\n",
    "        top_areas = df['Area'].value_counts().head(20)\n",
    "        # Create a new figure\n",
    "        fig, ax = plt.subplots(figsize=(8, 8))\n",
    "        # Plot a bar chart of the top 20 Areas\n",
    "        sns.barplot(x=top_areas.index, y=top_areas.values, palette='coolwarm',hue=top_areas.index)\n",
    "        # Rotate x-axis labels and set font size for readability\n",
    "        ax.set_xticklabels(ax.get_xticklabels(), rotation=80, fontsize=12)\n",
    "        # Set axis labels and title\n",
    "        ax.set_xlabel('Area', fontsize=14)\n",
    "        ax.set_ylabel('Frequency', fontsize=14)\n",
    "        ax.set_title('Top 20 Areas', fontsize=15)\n",
    "        # Optimize layout\n",
    "        plt.tight_layout()\n",
    "        # Show the plot\n",
    "        st.pyplot(fig)\n",
    "        \n",
    "        # Least 20 Areas\n",
    "        st.subheader(\"Least 20 Areas by Frequency\")\n",
    "        # Get top 20 most frequent Areas\n",
    "        least_areas = df['Area'].value_counts().tail(20)\n",
    "        # Create a new figure\n",
    "        fig, ax = plt.subplots(figsize=(8, 8))\n",
    "        # Plot a bar chart of the top 20 Areas\n",
    "        sns.barplot(x=least_areas.index, y=least_areas.values, palette='viridis',hue=least_areas.index)\n",
    "        # Rotate x-axis labels and set font size for readability\n",
    "        ax.set_xticklabels(ax.get_xticklabels(), rotation=80, fontsize=12)\n",
    "        # Set axis labels and title\n",
    "        ax.set_xlabel('Area', fontsize=14)\n",
    "        ax.set_ylabel('Frequency', fontsize=14)\n",
    "        ax.set_title('Least 20 Areas', fontsize=14)\n",
    "        # Optimize layout\n",
    "        plt.tight_layout()\n",
    "        # Show the plot\n",
    "        st.pyplot(fig)  \n",
    "\n",
    "        # Yield Trends Over Time \n",
    "        st.subheader(\"Yearly Yield Trends\")\n",
    "        # Group data by 'Year' and calculate the mean of 'hg/ha_yield'\n",
    "        yearly_yield = df.groupby('Year')['Hg/ha_yield'].mean()\n",
    "        # Create a line plot of average yield over time\n",
    "        fig, ax = plt.subplots(figsize=(8, 5))\n",
    "        yearly_yield.plot(ax=ax, color='orange', linewidth=2, marker='o')\n",
    "        # Set chart title and axis labels\n",
    "        ax.set_title('Average Crop Yield per Year (hg/ha)', fontsize=16)\n",
    "        ax.set_xlabel('Year', fontsize=14)\n",
    "        ax.set_ylabel('Average Yield (hg/ha)', fontsize=14)\n",
    "        ax.set_xticklabels(ax.get_xticklabels(), fontsize=12)\n",
    "        ax.set_yticklabels(ax.get_yticklabels(), fontsize=12)\n",
    "        # Add grid for better visual guidance\n",
    "        ax.grid(True, linestyle='--', alpha=0.6)\n",
    "        # Optimize layout\n",
    "        plt.tight_layout()\n",
    "        # Display the plot\n",
    "        st.pyplot(fig)\n",
    "\n",
    "        # Maximum Yield per Crop\n",
    "        st.subheader(\"Max Yield per Crop by Area\")\n",
    "        # Group by Crop and get the row with the highest yield per crop\n",
    "        best_crop = df.loc[df.groupby('Crop')['Hg/ha_yield'].idxmax()][['Crop', 'Area', 'Hg/ha_yield']]\n",
    "        # Create a bar plot of maximum yield per crop\n",
    "        fig, ax = plt.subplots(figsize=(8, 8))\n",
    "        sns.barplot(data=best_crop,x='Area', y='Hg/ha_yield', hue='Crop')\n",
    "        # Set the title and axis labels\n",
    "        ax.set_title('Maximum Yield per Crop by Area (hg/ha)', fontsize=16)\n",
    "        ax.set_xlabel('Area', fontsize=14)\n",
    "        ax.set_ylabel('Maximum Yield (hg/ha)', fontsize=14)\n",
    "        # Adjust tick label font sizes\n",
    "        ax.set_xticklabels(ax.get_xticklabels(), fontsize=12, rotation=45)\n",
    "        ax.set_yticklabels(ax.get_yticklabels(), fontsize=12)\n",
    "        # Resize and position the hue legend\n",
    "        ax.legend(title='Crop', title_fontsize=12, fontsize=10, loc='upper right', bbox_to_anchor=(1.15, 1))\n",
    "        # Tidy up layout\n",
    "        plt.tight_layout()\n",
    "        # Display the plot\n",
    "        st.pyplot(fig)\n",
    "\n",
    "        # Total Yield by Crop\n",
    "        st.subheader(\"Total Yield by Crop Type\")\n",
    "        # Group by crop and calculate **total** yield\n",
    "        yield_per_crop = df.groupby('Crop')['Hg/ha_yield'].sum()\n",
    "        # Plot using Seaborn\n",
    "        fig, ax= plt.subplots(figsize=(10, 6))\n",
    "        sns.barplot(x=yield_per_crop.values, y=yield_per_crop.index, color='orange', ax=ax)\n",
    "        # Set the title and axis labels\n",
    "        ax.set_title('Total Crop Yield (hg/ha)',  fontsize=16)\n",
    "        ax.set_xlabel('Yield (hg/ha)', fontsize=14)\n",
    "        ax.set_ylabel('Crop', fontsize=14)\n",
    "        # Optimize layout\n",
    "        plt.tight_layout()\n",
    "        st.pyplot(fig)\n",
    "\n",
    "        # Average Yield by Area\n",
    "        st.subheader(\"Average Yield by Area\")\n",
    "        # Group by Area and compute average yield\n",
    "        area_avg = df.groupby('Area')['Hg/ha_yield'].mean().reset_index()\n",
    "        area_avg.columns = ['Area', 'Hg/ha_yield']\n",
    "        # Find the country/area with the best average yield\n",
    "        best_area = area_avg.loc[area_avg['Hg/ha_yield'].idxmax()]\n",
    "        st.write(\"Country/Area with the best average yield:\")\n",
    "        st.write(best_area)\n",
    "        # Plot average yield per area\n",
    "        fig, ax = plt.subplots(figsize=(7, 13))\n",
    "        sns.barplot(data=area_avg, x='Hg/ha_yield', y='Area', hue='Area', palette=\"viridis\")\n",
    "        # Set the title and axis labels\n",
    "        ax.set_yticklabels(ax.get_yticklabels(), fontsize=9)\n",
    "        ax.set_xlabel('Average Yield (hg/ha)', fontsize=12)\n",
    "        ax.set_ylabel('Area', fontsize=12)\n",
    "        ax.set_title('Average Crop Yield by Area', fontsize=14)\n",
    "        # Optimize layout\n",
    "        plt.tight_layout()\n",
    "        st.pyplot(fig)\n",
    "\n",
    "        # Rainfall Trends\n",
    "        st.subheader(\"Average Rainfall per Year\")\n",
    "        # Group data by 'Year' and calculate the mean of 'hg/ha_yield'\n",
    "        rainfall_year = df.groupby('Year')['Average_rain_fall_mm_per_year'].mean()\n",
    "        # Create a line plot of average yield over time\n",
    "        fig, ax = plt.subplots(figsize=(8, 5))\n",
    "        rainfall_year.plot(color='red', linewidth=2, marker='o')\n",
    "        # Set chart title and axis labels\n",
    "        ax.set_title('Average Rainfall per Year', fontsize=16)\n",
    "        ax.set_xlabel('Year', fontsize=14)\n",
    "        ax.set_ylabel('Average Rainfall (mm)', fontsize=14)\n",
    "        ax.set_xticklabels(ax.get_xticklabels(), fontsize=12)\n",
    "        ax.set_yticklabels(ax.get_yticklabels(), fontsize=12)\n",
    "        # Add grid for better visual guidance\n",
    "        ax.grid(True, linestyle='--', alpha=0.6)\n",
    "        # Optimize layout\n",
    "        plt.tight_layout()\n",
    "        # Display the plot\n",
    "        st.pyplot(fig)\n",
    "\n",
    "        # Top 10 Areas by Rainfall\n",
    "        st.subheader(\"Top 10 Areas by Avg Rainfall\")\n",
    "        # Group by Area and calculate average rainfall\n",
    "        top_rain = df.groupby('Area')['Average_rain_fall_mm_per_year'].mean()\n",
    "        # Sort in descending order and get the top 10\n",
    "        top10_avg_rainfall = top_rain.sort_values(ascending=False).head(10)\n",
    "        # Convert to DataFrame for better handling\n",
    "        top10_df = top10_avg_rainfall.reset_index()\n",
    "        top10_df.columns = ['Area', 'Average_Rainfall']\n",
    "        # Plot\n",
    "        fig, ax = plt.subplots(figsize=(9,7))\n",
    "        sns.barplot(data=top10_df, x='Average_Rainfall', y='Area', \n",
    "                    palette='dark:orange', hue='Area')\n",
    "        # Chart styling\n",
    "        ax.set_title('Top 10 Countries by Average Rainfall', fontsize=18)\n",
    "        ax.set_xlabel('Average Rainfall (mm/year)', fontsize=15)\n",
    "        ax.set_ylabel('Country/Area', fontsize=15)\n",
    "        ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)\n",
    "        ax.set_yticklabels(ax.get_yticklabels(), fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        st.pyplot(fig)\n",
    "\n",
    "        # Rainfall vs Yield\n",
    "        st.subheader(\"Rainfall vs Crop Yield\")\n",
    "        # Plot\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        sns.scatterplot(data=df, x='Average_rain_fall_mm_per_year', \n",
    "                        y='Hg/ha_yield', hue='Crop', alpha=0.6, ax=ax)\n",
    "        ax.set_title('Effect of Rainfall on Crop Yield', fontsize=16)\n",
    "        ax.set_xlabel('Average Rainfall (mm/year)', fontsize=14)\n",
    "        ax.set_ylabel('Yield (hg/ha)', fontsize=14)\n",
    "        ax.set_xticklabels(ax.get_xticklabels(), fontsize=14)\n",
    "        ax.set_yticklabels(ax.get_yticklabels(), fontsize=14)\n",
    "        ax.legend(title='Country/Area', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        # plt.tight_layout()\n",
    "        st.pyplot(fig)                                                 \n",
    "\n",
    "        # Trend by Selected Crop \n",
    "        st.subheader(\"Trend Analysis by Crop\")        \n",
    "        # Filter the DataFrame by the selected crop\n",
    "        selected_crop = st.selectbox(\"Select a Crop\", sorted(df['Crop'].unique()))\n",
    "        df_crop = df[df['Crop'] == selected_crop]\n",
    "        \n",
    "        crop_metrics = {'Hg/ha_yield': ('Yield (hg/ha)', 'blue'),\n",
    "            'Pesticides_tonnes': ('Pesticides (tonnes)', 'black'),\n",
    "            'Average_rain_fall_mm_per_year': ('Rainfall (mm)', 'red'),\n",
    "            'Avg_temp': ('Avg Temperature (°C)', 'orange')}\n",
    "        \n",
    "        # Loop through each metric and create a time series plot\n",
    "        for col, (label, color) in crop_metrics.items():\n",
    "            fig, ax = plt.subplots(figsize=(10, 6))\n",
    "            # Plot mean values grouped by year\n",
    "            df_crop.groupby('Year')[col].mean().plot(ax=ax, color=color, marker='o')\n",
    "            # Add plot formatting\n",
    "            ax.set_title(f\"{label} over Years for {selected_crop}\", fontsize=16)\n",
    "            ax.set_xlabel(\"Year\", fontsize=14)\n",
    "            ax.set_ylabel(label, fontsize=14)\n",
    "            for label in ax.get_xticklabels():\n",
    "                label.set_fontsize(14)\n",
    "            for label in ax.get_yticklabels():\n",
    "                label.set_fontsize(14)\n",
    "            ax.legend()\n",
    "            ax.grid(True)\n",
    "            # Display the plot\n",
    "            plt.tight_layout()\n",
    "            # Display the plot in Streamlit\n",
    "            st.pyplot(fig)    \n",
    "    \n",
    "        # Country Specific Yield Trend \n",
    "        st.subheader(\"Country-Specific Yield Trends\")\n",
    "        selected_country = st.selectbox(\"Select a Country\", sorted(df['Area'].unique()))\n",
    "        filtered = df[df['Area'] == selected_country]\n",
    "        fig, ax = plt.subplots()\n",
    "        sns.lineplot(data=filtered, x='Year', y='Hg/ha_yield', hue='Crop', marker='o', ax=ax)\n",
    "        ax.set_title(f\"Crop Yield Over Time in {selected_country}\", fontsize=16)\n",
    "        ax.set_xlabel(\"Year\", fontsize=14)\n",
    "        ax.set_ylabel(\"Yield (hg/ha)\", fontsize=14)\n",
    "        for label in ax.get_xticklabels():\n",
    "            label.set_fontsize(14)\n",
    "        for label in ax.get_yticklabels():\n",
    "            label.set_fontsize(14)\n",
    "        st.pyplot(fig)\n",
    "\n",
    "        # Pesticide Usage\n",
    "        st.subheader(\"Pesticide Usage Overview\")\n",
    "        with st.expander(\"Top Countries by Pesticide Use\"):\n",
    "            top_pesticide = df.groupby('Area')['Pesticides_tonnes'].sum().sort_values(ascending=False).head(10)\n",
    "            fig, ax = plt.subplots()\n",
    "            sns.barplot(x=top_pesticide.values, y=top_pesticide.index, \n",
    "                        palette=\"Reds_r\", ax=ax, hue= top_pesticide.index)\n",
    "            ax.set_title(\"Top 10 Countries by Pesticide Use\", fontsize=16)\n",
    "            ax.set_xlabel(\"Total Pesticides Used (tonnes)\", fontsize=14)\n",
    "            ax.set_ylabel(\"Country\", fontsize=14)\n",
    "            for label in ax.get_xticklabels():\n",
    "                label.set_fontsize(14)\n",
    "            for label in ax.get_yticklabels():\n",
    "                label.set_fontsize(14)\n",
    "            st.pyplot(fig)        \n",
    "\n",
    "        with st.expander(\"Global Pesticide Use Over Time\"):\n",
    "            pesticide_trend = df.groupby('Year')['Pesticides_tonnes'].sum()\n",
    "            fig, ax = plt.subplots()\n",
    "            sns.lineplot(x=pesticide_trend.index, y=pesticide_trend.values, marker='o', ax=ax)\n",
    "            ax.set_title(\"Pesticide Use Over Time\", fontsize=16)\n",
    "            ax.set_xlabel(\"Year\", fontsize=14)\n",
    "            ax.set_ylabel(\"Global Pesticide Use Over Time\", fontsize=14)\n",
    "            for label in ax.get_xticklabels():\n",
    "                label.set_fontsize(14)\n",
    "            for label in ax.get_yticklabels():\n",
    "                label.set_fontsize(14)\n",
    "            st.pyplot(fig)\n",
    "\n",
    "        # Crop with Most Pesticide\n",
    "        with st.expander(\"Crops With Most Pesticide Used\"):\n",
    "            crop_pesticide = df.groupby('Crop')['Pesticides_tonnes'].sum().sort_values(ascending=False).head(10)\n",
    "            fig, ax = plt.subplots()\n",
    "            sns.barplot(x=crop_pesticide.values, y=crop_pesticide.index, palette=\"YlOrBr\", \n",
    "                        ax=ax, hue=crop_pesticide.index)\n",
    "            ax.set_title(\"Top 10 Crops by Pesticide Use\", fontsize=16)\n",
    "            ax.set_xlabel('Total Pesticides Used (tonnes)', fontsize=14)\n",
    "            ax.set_ylabel('Crop', fontsize=14)\n",
    "            plt.tight_layout()\n",
    "            for label in ax.get_xticklabels():\n",
    "                label.set_fontsize(14)\n",
    "            for label in ax.get_yticklabels():\n",
    "                label.set_fontsize(14)\n",
    "            st.pyplot(fig)\n",
    "        \n",
    "        # Yield & Environment\n",
    "        st.header(\"Yield vs Environment\")\n",
    "        with st.expander(\"Effect of Pesticide on Crop Yield\"):\n",
    "            fig, ax = plt.subplots()\n",
    "            sns.scatterplot(data=df, x='Pesticides_tonnes', y='Hg/ha_yield', hue='Crop', ax=ax)\n",
    "            ax.set_title(\"Pesticide vs Crop Yield\", fontsize=16)\n",
    "            ax.set_xlabel(\"Pesticides (tonnes)\", fontsize=14)\n",
    "            ax.set_ylabel(\"Yield (hg/ha)\",fontsize=14)\n",
    "            for label in ax.get_xticklabels():\n",
    "                label.set_fontsize(14)\n",
    "            for label in ax.get_yticklabels():\n",
    "                label.set_fontsize(14)\n",
    "            st.pyplot(fig)\n",
    "        \n",
    "        with st.expander(\"Effect of Temperature on Yield\"):\n",
    "            fig, ax = plt.subplots()\n",
    "            sns.scatterplot(data=df, x='Avg_temp', y='Hg/ha_yield', hue='Crop', ax=ax)\n",
    "            ax.set_title(\"Temperature vs Yield\", fontsize=16)\n",
    "            ax.set_xlabel(\"Temperature (°C)\", fontsize=14)\n",
    "            ax.set_ylabel(\"Yield (hg/ha)\", fontsize=14)\n",
    "            for label in ax.get_xticklabels():\n",
    "                label.set_fontsize(14)\n",
    "            for label in ax.get_yticklabels():\n",
    "                label.set_fontsize(14)\n",
    "            st.pyplot(fig)\n",
    "\n",
    "        # Rainfall & Temperature\n",
    "        st.header(\"Rainfall and Temperature\")\n",
    "        col1, col2 = st.columns(2)\n",
    "        with col1:\n",
    "            st.subheader(\"Average Temperature by Year\")\n",
    "            avg_temp_year = df.groupby('Year')['Avg_temp'].mean()\n",
    "            fig, ax = plt.subplots()\n",
    "            sns.lineplot(x=avg_temp_year.index, y=avg_temp_year.values, marker='o', ax=ax)\n",
    "            ax.set_title(\"Avg. Temperature Over Years\", fontsize=16)\n",
    "            ax.set_xlabel(\"Year\", fontsize=14)\n",
    "            ax.set_ylabel(\"Temperature (°C)\", fontsize=14)\n",
    "            for label in ax.get_xticklabels():\n",
    "                label.set_fontsize(14)\n",
    "            for label in ax.get_yticklabels():\n",
    "                label.set_fontsize(14)\n",
    "            st.pyplot(fig)\n",
    "        \n",
    "        with col2:\n",
    "            st.subheader(\"Average Rainfall by Year\")\n",
    "            avg_rain_year = df.groupby('Year')['Average_rain_fall_mm_per_year'].mean()\n",
    "            fig, ax = plt.subplots()\n",
    "            sns.lineplot(x=avg_rain_year.index, y=avg_rain_year.values, marker='o', ax=ax)\n",
    "            ax.set_title(\"Avg. Rainfall Over Years\", fontsize=16)\n",
    "            ax.set_xlabel(\"Year\", fontsize=14)\n",
    "            ax.set_ylabel(\"Rainfall (mm)\", fontsize=14)\n",
    "            for label in ax.get_xticklabels():\n",
    "                label.set_fontsize(14)\n",
    "            for label in ax.get_yticklabels():\n",
    "                label.set_fontsize(14)\n",
    "            st.pyplot(fig)\n",
    "\n",
    "        # Pesticide vs Yield Scatterplot\n",
    "        st.header(\"Pesticide Use vs Crop Yield\")\n",
    "        avg_data_country = df.groupby('Area')[['Pesticides_tonnes', 'Hg/ha_yield']].mean().dropna()\n",
    "        fig, ax = plt.subplots()\n",
    "        sns.scatterplot(data=avg_data_country, x='Pesticides_tonnes', y='Hg/ha_yield')\n",
    "        ax.set_title('Average Pesticide Use vs Crop Yield by Country')\n",
    "        ax.set_xlabel('Average Pesticide Use (tonnes)')\n",
    "        ax.set_ylabel('Average Yield (hg/ha)')\n",
    "        st.pyplot(fig)\n",
    "\n",
    "        # Top 10 Countries by Average Temperature\n",
    "        st.header(\"Top 10 Hottest Countries (Avg. Temp)\")\n",
    "        # Average temperature by country (Top 10 warmest)\n",
    "        fig, ax = plt.subplots()\n",
    "        avg_temp_country = df.groupby('Area')['Avg_temp'].mean().sort_values(ascending=False).head(10)\n",
    "        sns.barplot(x=avg_temp_country.values, y=avg_temp_country.index, palette=\"coolwarm\", hue=avg_temp_country.index)\n",
    "        ax.set_title('Top 10 Countries by Average Temperature')\n",
    "        ax.set_xlabel('Average Temperature (°C)')\n",
    "        ax.set_ylabel('Country')\n",
    "        st.pyplot(fig)\n",
    "\n",
    "        # Set seaborn style\n",
    "        sns.set(style='whitegrid', palette='Set2')\n",
    "        # Rainfall vs Pesticide Use\n",
    "        st.header(\"Rainfall vs Pesticide Use by Crop\")\n",
    "        # Scatterplot: Relationship between Rainfall and Pesticide Use\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        sns.scatterplot(data=df, x='Average_rain_fall_mm_per_year', y='Pesticides_tonnes', hue='Crop', alpha=0.7)\n",
    "        ax.set_title('Rainfall vs Pesticide Use by Crop')\n",
    "        ax.set_xlabel('Average Rainfall (mm/year)')\n",
    "        ax.set_ylabel('Pesticide Use (tonnes)')\n",
    "        ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        st.pyplot(fig)\n",
    "        \n",
    "        # KDE + Barplot for Rainfall, Pesticides, Temperature, and Yield\n",
    "        st.header(\"Distributions: Rainfall, Pesticides, Temperature, and Yield\")        \n",
    "        fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "        sns.histplot(df['Average_rain_fall_mm_per_year'], kde=True, ax=axes[0, 0], color='blue')\n",
    "        axes[0, 0].set_title('Average Rainfall Distribution')\n",
    "        sns.histplot(df['Pesticides_tonnes'], kde=True, ax=axes[0, 1], color='green')\n",
    "        axes[0, 1].set_title('Pesticide Usage Distribution')\n",
    "        sns.histplot(df['Avg_temp'], kde=True, ax=axes[1, 0], color='orange')\n",
    "        axes[1, 0].set_title('Average Temperature Distribution')\n",
    "        sns.histplot(df['Hg/ha_yield'], kde=True, ax=axes[1, 1], color='purple')\n",
    "        axes[1, 1].set_title('Crop Yield Distribution')\n",
    "        plt.tight_layout()\n",
    "        st.pyplot(fig)\n",
    "        \n",
    "        # Boxplot: Temperature Needed by Various Crops\n",
    "        st.header(\"Temperature Distribution by Crop\")\n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        sns.boxplot(data=df, x='Crop', y='Avg_temp', palette='coolwarm', hue='Crop')\n",
    "        ax.set_title('Temperature Distribution for Each Crop')\n",
    "        ax.set_xlabel('Crop')\n",
    "        ax.set_ylabel('Average Temperature (°C)')\n",
    "        for label in ax.get_xticklabels():\n",
    "            label.set_fontsize(14)\n",
    "        for label in ax.get_yticklabels():\n",
    "                label.set_fontsize(14)\n",
    "        st.pyplot(fig)\n",
    "        \n",
    "        # Average Yield per Year by Crop\n",
    "        st.header(\"Average Crop Yield per Year\") \n",
    "        fig, ax = plt.subplots(figsize=(14, 7))\n",
    "        sns.lineplot(data=df, x='Year', y='Hg/ha_yield', hue='Crop', estimator='mean', errorbar=None)\n",
    "        ax.set_title('Average Crop Yield per Year')\n",
    "        ax.set_xlabel('Year')\n",
    "        ax.set_ylabel('Yield (hg/ha)')\n",
    "        ax.legend(title='Crop', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        st.pyplot(fig)\n",
    "    else:\n",
    "        # Message shown if user tries to access this step before uploading data\n",
    "        st.warning(\"Please upload a dataset first in the 'Upload Data' section.\")\n",
    "\n",
    "elif options == \"Visualization\" and st.session_state.cleaned_df is None:\n",
    "    st.warning(\"Please clean your data first in the 'Data Cleaning' section.\")\n",
    "\n",
    "# STEP 4: Preprocessing\n",
    "elif options == \"Preprocessing\":\n",
    "    st.header(\"Data Preprocessing\")\n",
    "\n",
    "    # Ensure the cleaned dataframe exists in session state\n",
    "    if st.session_state.cleaned_df is not None:\n",
    "        df = st.session_state.cleaned_df.copy()\n",
    "\n",
    "        \n",
    "        st.subheader(\"Encoding Categorical Features\")\n",
    "        # Function to encode categorical features using LabelEncoder\n",
    "        def encode_categorical(dataframe, columns):\n",
    "            encoder = LabelEncoder()\n",
    "            for col in columns:\n",
    "                dataframe[col] = encoder.fit_transform(dataframe[col])\n",
    "            return dataframe\n",
    "\n",
    "        # Identify categorical columns\n",
    "        categorical_columns = df.select_dtypes(include=\"object\").columns.tolist()\n",
    "\n",
    "        # Encode them\n",
    "        df = encode_categorical(df, categorical_columns)\n",
    "        st.success(\"Categorical features encoded successfully!\")\n",
    "        st.dataframe(df.head())\n",
    "\n",
    "        \n",
    "        st.subheader(\"Correlation Analysis\")\n",
    "        # Compute correlation matrix\n",
    "        correlation_matrix = df.corr()\n",
    "        # Visualize correlation matrix\n",
    "        fig, ax = plt.subplots(figsize=(8, 8))\n",
    "        sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5, ax=ax)\n",
    "        ax.set_title('Heatmap of Correlation Matrix', fontsize=18)\n",
    "        st.pyplot(fig)\n",
    "\n",
    "        # Function to find highly correlated feature pairs above a threshold\n",
    "        def find_high_correlation_pairs(corr_matrix, threshold=0.5):\n",
    "            corr_pairs = []\n",
    "            columns = corr_matrix.columns\n",
    "            for i in range(len(columns)):\n",
    "                for j in range(i + 1, len(columns)):\n",
    "                    value = corr_matrix.iloc[i, j]\n",
    "                    if abs(value) >= threshold:\n",
    "                        corr_pairs.append((columns[i], columns[j], value))\n",
    "            return corr_pairs\n",
    "\n",
    "        # Check for highly correlated feature pairs (above or below ±0.5)\n",
    "        high_corr_columns = find_high_correlation_pairs(df.corr(), threshold=0.5)\n",
    "        st.subheader(\"Highly Correlated Feature Pairs ≥ ±0.5)\")\n",
    "\n",
    "        if high_corr_columns:\n",
    "            for col1, col2, corr_val in high_corr_columns:\n",
    "                st.write(f\"Correlation between `{col1}` and `{col2}` is `{corr_val:.2f}`\")\n",
    "        else:\n",
    "            st.info(\"No highly correlated feature pairs found.\")\n",
    "\n",
    "        # Function to drop one column from each highly correlated pair\n",
    "        def drop_highly_correlated_features(dataframe, corr_matrix, threshold=0.5):\n",
    "            to_drop = set()\n",
    "            for i in range(len(corr_matrix.columns)):\n",
    "                for j in range(i + 1, len(corr_matrix.columns)):\n",
    "                    col1 = corr_matrix.columns[i]\n",
    "                    col2 = corr_matrix.columns[j]\n",
    "                    if abs(corr_matrix.iloc[i, j]) > threshold:\n",
    "                        # Drop the second column in the pair\n",
    "                        to_drop.add(col2)\n",
    "            dataframe = dataframe.drop(columns=list(to_drop))\n",
    "            return dataframe, list(to_drop)\n",
    "\n",
    "        # Drop correlated features\n",
    "        df, dropped_cols = drop_highly_correlated_features(df, correlation_matrix, threshold=0.5)\n",
    "\n",
    "        # Display dropped columns if any\n",
    "        if dropped_cols:\n",
    "            st.subheader(\"Dropped Highly Correlated Columns\")\n",
    "            st.write(f\"Columns dropped due to high correlation (>|0.5|): `{', '.join(dropped_cols)}`\")\n",
    "        else:\n",
    "            st.info(\"No highly correlated features were dropped.\")\n",
    "\n",
    "        st.subheader(\"Target and Feature Separation\")\n",
    "        # Ensure target column exists\n",
    "        if 'Hg/ha_yield' in df.columns:\n",
    "            st.write(\"Target Column Selected: `'Hg/ha_yield'`\")\n",
    "\n",
    "            # Split into features and target\n",
    "            X = df.drop('Hg/ha_yield', axis=1)\n",
    "            Y = df['Hg/ha_yield']\n",
    "\n",
    "            st.write(\"Feature Columns:\")\n",
    "            st.write(X.columns)\n",
    "        else:\n",
    "            st.error(\"Target column `'Hg/ha_yield'` not found. Please check your dataset.\")\n",
    "            st.stop()\n",
    "\n",
    "        \n",
    "        st.subheader(\"Feature Scaling (Standard Normalization)\")\n",
    "         # Function to normalize features\n",
    "        def normalize_features(features):\n",
    "            scaler = StandardScaler()\n",
    "            scaled = scaler.fit_transform(features)\n",
    "            return pd.DataFrame(scaled, columns=features.columns)\n",
    "\n",
    "        # Apply normalization\n",
    "        X = normalize_features(X)\n",
    "        st.success(\"Features normalized successfully!\")\n",
    "\n",
    "        # Store processed features and target in session state\n",
    "        st.session_state.X_processed = X\n",
    "        st.session_state.Y_processed = Y\n",
    "\n",
    "        st.success(\"Data preprocessing complete!\")\n",
    "\n",
    "    else:\n",
    "        # Data not available warning\n",
    "        st.warning(\"Please upload a dataset first in the 'Upload Data' section.\")\n",
    "\n",
    "# Fallback: Prevents error if accessed before cleaning\n",
    "elif options == \"Preprocessing\" and st.session_state.cleaned_df is None:\n",
    "    st.warning(\"Please clean your data first in the 'Data Cleaning' section.\")\n",
    "\n",
    "        \n",
    "        \n",
    "# # STEP 5: Model Training\n",
    "# st.subheader(\"🤖 Model Development\")\n",
    "\n",
    "# test_size = st.slider(\"Select test size\", 0.1, 0.5, 0.2)\n",
    "# random_state = st.number_input(\"Random state (for reproducibility)\", value=42)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=test_size, random_state=int(random_state))\n",
    "\n",
    "# model = RandomForestClassifier()\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "# y_pred = model.predict(X_test)\n",
    "\n",
    "# # STEP 6: Evaluation\n",
    "# st.subheader(\"📋 Model Evaluation\")\n",
    "# st.write(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "# st.text(\"Classification Report:\")\n",
    "# st.text(classification_report(y_test, y_pred))\n",
    "\n",
    "# # Predict with user input\n",
    "# st.subheader(\"📝 Make a Prediction\")\n",
    "# input_data = {}\n",
    "# for col in df.drop(columns=[target_col]).columns:\n",
    "#     value = st.text_input(f\"Enter value for {col}\")\n",
    "#     input_data[col] = value\n",
    "\n",
    "# if st.button(\"Predict\"):\n",
    "#     input_df = pd.DataFrame([input_data])\n",
    "\n",
    "#     for col in input_df.columns:\n",
    "#         if input_df[col].dtype == 'object':\n",
    "#             input_df[col] = LabelEncoder().fit(df[col]).transform(input_df[col])\n",
    "\n",
    "#     input_df_scaled = scaler.transform(input_df)\n",
    "#     prediction = model.predict(input_df_scaled)\n",
    "#     st.success(f\"🎉 Predicted class: {prediction[0]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
