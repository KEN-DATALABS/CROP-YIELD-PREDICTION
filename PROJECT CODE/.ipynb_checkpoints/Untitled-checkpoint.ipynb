{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de50c99d-c90e-460a-8509-6eac5d9492e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "import plotly.express as px\n",
    "from ydate_profiling import ProfileReport\n",
    "import datetime\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "# Set page config\n",
    "st.set_page_config(page_title=\"Data Solution\", layout=\"wide\")\n",
    "\n",
    "# Title\n",
    "st.title(\"Data Solution\")\n",
    "st.markdown(\"\"\"\n",
    "This app performs automated data analysis, visualization, and predictive modeling. \n",
    "Upload your dataset and follow the steps to get insights!\n",
    "\"\"\")\n",
    "\n",
    "# Sidebar for navigation\n",
    "st.sidebar.title(\"Navigation\")\n",
    "options = st.sidebar.radio(\"Select Step:\", \n",
    "                          [\"Upload Data\", \"Data Cleaning\", \"EDA\", \n",
    "                           \"Visualization\", \"Prediction\", \"Insights\"])\n",
    "\n",
    "# Initialize session state\n",
    "if 'df' not in st.session_state:\n",
    "    st.session_state.df = None\n",
    "if 'cleaned_df' not in st.session_state:\n",
    "    st.session_state.cleaned_df = None\n",
    "if 'target' not in st.session_state:\n",
    "    st.session_state.target = None\n",
    "if 'model_type' not in st.session_state:\n",
    "    st.session_state.model_type = None\n",
    "if 'model' not in st.session_state:\n",
    "    st.session_state.model = None\n",
    "if 'report' not in st.session_state:\n",
    "    st.session_state.report = None\n",
    "\n",
    "# Step 1: Upload Data\n",
    "if options == \"Upload Data\":\n",
    "    st.header(\"Upload Your Dataset\")\n",
    "    uploaded_file = st.file_uploader(\"Choose a CSV or Excel file\", type=[\"csv\", \"xlsx\"])\n",
    "    \n",
    "    if uploaded_file is not None:\n",
    "        try:\n",
    "            if uploaded_file.name.endswith('.csv'):\n",
    "                df = pd.read_csv(uploaded_file)\n",
    "            else:\n",
    "                df = pd.read_excel(uploaded_file)\n",
    "            \n",
    "            st.session_state.df = df\n",
    "            st.success(\"Data uploaded successfully!\")\n",
    "            \n",
    "            st.subheader(\"Data Preview\")\n",
    "            st.write(df.head())\n",
    "            \n",
    "            st.subheader(\"Basic Information\")\n",
    "            st.write(f\"Number of rows: {df.shape[0]}\")\n",
    "            st.write(f\"Number of columns: {df.shape[1]}\")\n",
    "            \n",
    "            # Basic stats\n",
    "            st.subheader(\"Basic Statistics\")\n",
    "            st.write(df.describe(include='all'))\n",
    "            \n",
    "            # Detect data types\n",
    "            st.subheader(\"Data Types\")\n",
    "            dtype_df = pd.DataFrame(df.dtypes, columns=['Data Type'])\n",
    "            st.write(dtype_df)\n",
    "            \n",
    "            # Detect missing values\n",
    "            st.subheader(\"Missing Values\")\n",
    "            missing_df = pd.DataFrame(df.isna().sum(), columns=['Missing Values'])\n",
    "            missing_df['Percentage'] = (missing_df['Missing Values'] / len(df)) * 100\n",
    "            st.write(missing_df)\n",
    "            \n",
    "            # Detect duplicates\n",
    "            st.subheader(\"Duplicate Rows\")\n",
    "            st.write(f\"Number of duplicate rows: {df.duplicated().sum()}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            st.error(f\"Error loading file: {e}\")\n",
    "\n",
    "# Step 2: Data Cleaning\n",
    "elif options == \"Data Cleaning\" and st.session_state.df is not None:\n",
    "    st.header(\"Data Cleaning\")\n",
    "    df = st.session_state.df\n",
    "    \n",
    "    st.subheader(\"Data Issues Detected\")\n",
    "    \n",
    "    # Create a list of issues\n",
    "    issues = []\n",
    "    \n",
    "    # Check for missing values\n",
    "    missing_values = df.isna().sum().sum()\n",
    "    if missing_values > 0:\n",
    "        issues.append(f\"Missing values detected: {missing_values} total missing values\")\n",
    "    \n",
    "    # Check for duplicates\n",
    "    duplicates = df.duplicated().sum()\n",
    "    if duplicates > 0:\n",
    "        issues.append(f\"Duplicate rows detected: {duplicates} duplicates\")\n",
    "    \n",
    "    # Check for outliers (simple check)\n",
    "    numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "    for col in numeric_cols:\n",
    "        if (df[col].max() > df[col].mean() + 3 * df[col].std()) or \\\n",
    "           (df[col].min() < df[col].mean() - 3 * df[col].std()):\n",
    "            issues.append(f\"Potential outliers detected in column: {col}\")\n",
    "    \n",
    "    # Check for inconsistent data types\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            try:\n",
    "                pd.to_numeric(df[col])\n",
    "                issues.append(f\"Column '{col}' contains numeric data but is stored as text\")\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    # Display issues\n",
    "    if issues:\n",
    "        st.warning(\"The following issues were detected in your dataset:\")\n",
    "        for issue in issues:\n",
    "            st.write(f\"- {issue}\")\n",
    "    else:\n",
    "        st.success(\"No major data quality issues detected!\")\n",
    "    \n",
    "    # Cleaning options\n",
    "    st.subheader(\"Data Cleaning Options\")\n",
    "    \n",
    "    cleaning_options = st.multiselect(\n",
    "        \"Select cleaning operations to perform:\",\n",
    "        [\n",
    "            \"Remove duplicate rows\",\n",
    "            \"Fill missing values (numeric)\",\n",
    "            \"Fill missing values (categorical)\",\n",
    "            \"Remove rows with missing values\",\n",
    "            \"Remove columns with high missing values (>30%)\",\n",
    "            \"Convert text to numeric where possible\",\n",
    "            \"Remove outliers (for numeric columns)\",\n",
    "            \"Standardize column names\"\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    if st.button(\"Clean Data\"):\n",
    "        cleaned_df = df.copy()\n",
    "        \n",
    "        # Apply selected cleaning operations\n",
    "        if \"Remove duplicate rows\" in cleaning_options:\n",
    "            cleaned_df = cleaned_df.drop_duplicates()\n",
    "        \n",
    "        if \"Fill missing values (numeric)\" in cleaning_options:\n",
    "            numeric_cols = cleaned_df.select_dtypes(include=['int64', 'float64']).columns\n",
    "            imputer = SimpleImputer(strategy='mean')\n",
    "            cleaned_df[numeric_cols] = imputer.fit_transform(cleaned_df[numeric_cols])\n",
    "        \n",
    "        if \"Fill missing values (categorical)\" in cleaning_options:\n",
    "            cat_cols = cleaned_df.select_dtypes(include=['object']).columns\n",
    "            for col in cat_cols:\n",
    "                cleaned_df[col] = cleaned_df[col].fillna(cleaned_df[col].mode()[0])\n",
    "        \n",
    "        if \"Remove rows with missing values\" in cleaning_options:\n",
    "            cleaned_df = cleaned_df.dropna()\n",
    "        \n",
    "        if \"Remove columns with high missing values (>30%)\" in cleaning_options:\n",
    "            threshold = len(cleaned_df) * 0.3\n",
    "            cleaned_df = cleaned_df.dropna(axis=1, thresh=threshold)\n",
    "        \n",
    "        if \"Convert text to numeric where possible\" in cleaning_options:\n",
    "            for col in cleaned_df.columns:\n",
    "                if cleaned_df[col].dtype == 'object':\n",
    "                    try:\n",
    "                        cleaned_df[col] = pd.to_numeric(cleaned_df[col])\n",
    "                    except:\n",
    "                        pass\n",
    "        \n",
    "        if \"Remove outliers (for numeric columns)\" in cleaning_options:\n",
    "            numeric_cols = cleaned_df.select_dtypes(include=['int64', 'float64']).columns\n",
    "            for col in numeric_cols:\n",
    "                mean = cleaned_df[col].mean()\n",
    "                std = cleaned_df[col].std()\n",
    "                cleaned_df = cleaned_df[(cleaned_df[col] <= mean + 3*std) & \n",
    "                                      (cleaned_df[col] >= mean - 3*std)]\n",
    "        \n",
    "        if \"Standardize column names\" in cleaning_options:\n",
    "            cleaned_df.columns = cleaned_df.columns.str.lower().str.replace(' ', '_')\n",
    "        \n",
    "        st.session_state.cleaned_df = cleaned_df\n",
    "        st.success(\"Data cleaning completed!\")\n",
    "        \n",
    "        st.subheader(\"Cleaned Data Preview\")\n",
    "        st.write(cleaned_df.head())\n",
    "        \n",
    "        st.subheader(\"Cleaning Report\")\n",
    "        st.write(f\"Original shape: {df.shape}\")\n",
    "        st.write(f\"New shape: {cleaned_df.shape}\")\n",
    "        st.write(f\"Rows removed: {df.shape[0] - cleaned_df.shape[0]}\")\n",
    "        st.write(f\"Columns removed: {df.shape[1] - cleaned_df.shape[1]}\")\n",
    "\n",
    "elif options == \"Data Cleaning\" and st.session_state.df is None:\n",
    "    st.warning(\"Please upload a dataset first in the 'Upload Data' section.\")\n",
    "\n",
    "# Step 3: EDA\n",
    "elif options == \"EDA\" and st.session_state.cleaned_df is not None:\n",
    "    st.header(\"Exploratory Data Analysis (EDA)\")\n",
    "    df = st.session_state.cleaned_df\n",
    "    \n",
    "    st.subheader(\"Automated EDA Report\")\n",
    "    \n",
    "    if st.button(\"Generate Full EDA Report\"):\n",
    "        try:\n",
    "            # Create a temporary file for the report\n",
    "            with tempfile.NamedTemporaryFile(delete=False, suffix='.html') as tmpfile:\n",
    "                report_path = tmpfile.name\n",
    "            \n",
    "            # Generate the profile report\n",
    "            profile = ProfileReport(df, title=\"Profiling Report\")\n",
    "            profile.to_file(report_path)\n",
    "            \n",
    "            # Store the report path in session state\n",
    "            st.session_state.report = report_path\n",
    "            \n",
    "            # Display in Streamlit\n",
    "            with open(report_path, 'r') as f:\n",
    "                html_content = f.read()\n",
    "            \n",
    "            st.components.v1.html(html_content, height=1000, scrolling=True)\n",
    "            \n",
    "            # Add download button\n",
    "            with open(report_path, 'rb') as f:\n",
    "                st.download_button(\n",
    "                    label=\"Download EDA Report\",\n",
    "                    data=f,\n",
    "                    file_name=\"data_profile_report.html\",\n",
    "                    mime=\"text/html\"\n",
    "                )\n",
    "            \n",
    "        except Exception as e:\n",
    "            st.error(f\"Error generating report: {e}\")\n",
    "    \n",
    "    st.subheader(\"Quick Insights\")\n",
    "    \n",
    "    # Numeric columns analysis\n",
    "    numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "    if len(numeric_cols) > 0:\n",
    "        st.write(\"### Numeric Columns Analysis\")\n",
    "        \n",
    "        col1, col2 = st.columns(2)\n",
    "        \n",
    "        with col1:\n",
    "            selected_num_col = st.selectbox(\"Select numeric column:\", numeric_cols)\n",
    "            st.write(f\"**Statistics for {selected_num_col}**\")\n",
    "            st.write(df[selected_num_col].describe())\n",
    "            \n",
    "        with col2:\n",
    "            fig, ax = plt.subplots()\n",
    "            sns.histplot(df[selected_num_col], kde=True, ax=ax)\n",
    "            st.pyplot(fig)\n",
    "        \n",
    "        # Correlation matrix\n",
    "        if len(numeric_cols) > 1:\n",
    "            st.write(\"### Correlation Matrix\")\n",
    "            corr = df[numeric_cols].corr()\n",
    "            fig, ax = plt.subplots(figsize=(10, 8))\n",
    "            sns.heatmap(corr, annot=True, fmt=\".2f\", cmap='coolwarm', ax=ax)\n",
    "            st.pyplot(fig)\n",
    "    \n",
    "    # Categorical columns analysis\n",
    "    cat_cols = df.select_dtypes(include=['object']).columns\n",
    "    if len(cat_cols) > 0:\n",
    "        st.write(\"### Categorical Columns Analysis\")\n",
    "        \n",
    "        selected_cat_col = st.selectbox(\"Select categorical column:\", cat_cols)\n",
    "        \n",
    "        col1, col2 = st.columns(2)\n",
    "        \n",
    "        with col1:\n",
    "            st.write(f\"**Value Counts for {selected_cat_col}**\")\n",
    "            st.write(df[selected_cat_col].value_counts())\n",
    "            \n",
    "        with col2:\n",
    "            fig, ax = plt.subplots()\n",
    "            df[selected_cat_col].value_counts().plot(kind='bar', ax=ax)\n",
    "            st.pyplot(fig)\n",
    "\n",
    "elif options == \"EDA\" and st.session_state.cleaned_df is None:\n",
    "    st.warning(\"Please clean your data first in the 'Data Cleaning' section.\")\n",
    "\n",
    "# Step 4: Visualization (updated with filters)\n",
    "elif options == \"Visualization\" and st.session_state.cleaned_df is not None:\n",
    "    st.header(\"Data Visualization\")\n",
    "    df = st.session_state.cleaned_df\n",
    "    \n",
    "    st.subheader(\"Select Visualization Type\")\n",
    "    \n",
    "    viz_type = st.selectbox(\n",
    "        \"Choose visualization type:\",\n",
    "        [\n",
    "            \"Scatter Plot\",\n",
    "            \"Line Chart\",\n",
    "            \"Bar Chart\",\n",
    "            \"Histogram\",\n",
    "            \"Box Plot\",\n",
    "            \"Violin Plot\",\n",
    "            \"Pie Chart\",\n",
    "            \"Heatmap\",\n",
    "            \"Pair Plot\"\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Common options\n",
    "    numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "    cat_cols = df.select_dtypes(include=['object']).columns\n",
    "    \n",
    "    # New: Filter section\n",
    "    st.subheader(\"Data Filters\")\n",
    "    \n",
    "    # Create filter columns\n",
    "    col1, col2 = st.columns(2)\n",
    "    \n",
    "    with col1:\n",
    "        # Top/Bottom N filter\n",
    "        filter_type = st.selectbox(\n",
    "            \"Filter data by:\",\n",
    "            [\"None\", \"Top N values\", \"Bottom N values\", \"Range filter\"]\n",
    "        )\n",
    "        \n",
    "        if filter_type != \"None\":\n",
    "            if filter_type in [\"Top N values\", \"Bottom N values\"]:\n",
    "                n_values = st.number_input(\n",
    "                    \"Number of values:\",\n",
    "                    min_value=1,\n",
    "                    max_value=100,\n",
    "                    value=10\n",
    "                )\n",
    "                filter_column = st.selectbox(\n",
    "                    \"Filter by column:\",\n",
    "                    numeric_cols if filter_type in [\"Top N values\", \"Bottom N values\"] else df.columns\n",
    "                )\n",
    "            elif filter_type == \"Range filter\":\n",
    "                range_column = st.selectbox(\n",
    "                    \"Select column for range filter:\",\n",
    "                    numeric_cols\n",
    "                )\n",
    "                min_val, max_val = float(df[range_column].min()), float(df[range_column].max())\n",
    "                selected_min, selected_max = st.slider(\n",
    "                    \"Select range:\",\n",
    "                    min_value=min_val,\n",
    "                    max_value=max_val,\n",
    "                    value=(min_val, max_val)\n",
    "                )\n",
    "\n",
    "    with col2:\n",
    "        # Age band filter (if 'age' column exists)\n",
    "        if 'age' in df.columns:\n",
    "            age_filter = st.checkbox(\"Filter by age bands\")\n",
    "            if age_filter:\n",
    "                age_bins = st.slider(\n",
    "                    \"Age range:\",\n",
    "                    min_value=int(df['age'].min()),\n",
    "                    max_value=int(df['age'].max()),\n",
    "                    value=(int(df['age'].min()), int(df['age'].max()))\n",
    "                )\n",
    "                age_step = st.number_input(\"Age band size:\", min_value=1, max_value=20, value=5)\n",
    "    \n",
    "    # Apply filters to data\n",
    "    filtered_df = df.copy()\n",
    "    \n",
    "    if filter_type == \"Top N values\":\n",
    "        filtered_df = filtered_df.nlargest(n_values, filter_column)\n",
    "    elif filter_type == \"Bottom N values\":\n",
    "        filtered_df = filtered_df.nsmallest(n_values, filter_column)\n",
    "    elif filter_type == \"Range filter\":\n",
    "        filtered_df = filtered_df[\n",
    "            (filtered_df[range_column] >= selected_min) & \n",
    "            (filtered_df[range_column] <= selected_max)\n",
    "        ]\n",
    "    \n",
    "    if 'age' in df.columns and age_filter:\n",
    "        filtered_df = filtered_df[\n",
    "            (filtered_df['age'] >= age_bins[0]) & \n",
    "            (filtered_df['age'] <= age_bins[1])\n",
    "        ]\n",
    "        # Add age bands if selected\n",
    "        if st.checkbox(\"Group by age bands\"):\n",
    "            bins = list(range(age_bins[0], age_bins[1]+age_step, age_step))\n",
    "            labels = [f\"{i}-{i+age_step-1}\" for i in bins[:-1]]\n",
    "            filtered_df['age_band'] = pd.cut(\n",
    "                filtered_df['age'],\n",
    "                bins=bins,\n",
    "                labels=labels,\n",
    "                right=False\n",
    "            )\n",
    "    \n",
    "    # Visualization code (updated to use filtered_df instead of df)\n",
    "    if viz_type == \"Scatter Plot\":\n",
    "        if len(numeric_cols) >= 2:\n",
    "            x_axis = st.selectbox(\"X-axis\", numeric_cols)\n",
    "            y_axis = st.selectbox(\"Y-axis\", numeric_cols)\n",
    "            hue = st.selectbox(\"Hue (optional)\", [None] + list(cat_cols))\n",
    "            \n",
    "            fig = px.scatter(filtered_df, x=x_axis, y=y_axis, color=hue, \n",
    "                            title=f\"{y_axis} vs {x_axis} (Filtered)\")\n",
    "            st.plotly_chart(fig)\n",
    "        else:\n",
    "            st.warning(\"Need at least 2 numeric columns for scatter plot\")\n",
    "    \n",
    "    elif viz_type == \"Bar Chart\":\n",
    "        if len(cat_cols) >= 1 and len(numeric_cols) >= 1:\n",
    "            x_axis = st.selectbox(\"X-axis\", cat_cols)\n",
    "            y_axis = st.selectbox(\"Y-axis\", numeric_cols)\n",
    "            hue = st.selectbox(\"Hue (optional)\", [None] + list(cat_cols))\n",
    "            \n",
    "            # Use age_band if available\n",
    "            if 'age_band' in filtered_df.columns and x_axis == 'age':\n",
    "                x_axis = 'age_band'\n",
    "            \n",
    "            fig = px.bar(filtered_df, x=x_axis, y=y_axis, color=hue, \n",
    "                         title=f\"{y_axis} by {x_axis} (Filtered)\")\n",
    "            st.plotly_chart(fig)\n",
    "        else:\n",
    "            st.warning(\"Need at least 1 categorical and 1 numeric column for bar chart\")\n",
    "    \n",
    "    elif viz_type == \"Histogram\":\n",
    "        if len(numeric_cols) >= 1:\n",
    "            col = st.selectbox(\"Select column:\", numeric_cols)\n",
    "            bins = st.slider(\"Number of bins:\", 5, 100, 20)\n",
    "            \n",
    "            fig = px.histogram(filtered_df, x=col, nbins=bins, \n",
    "                              title=f\"Distribution of {col} (Filtered)\")\n",
    "            st.plotly_chart(fig)\n",
    "        else:\n",
    "            st.warning(\"Need at least 1 numeric column for histogram\")\n",
    "    \n",
    "    elif viz_type == \"Box Plot\":\n",
    "        if len(numeric_cols) >= 1:\n",
    "            y_axis = st.selectbox(\"Y-axis (numeric):\", numeric_cols)\n",
    "            x_axis = st.selectbox(\"X-axis (optional - categorical):\", [None] + list(cat_cols))\n",
    "            \n",
    "            fig = px.box(filtered_df, x=x_axis, y=y_axis, \n",
    "                         title=f\"Box Plot of {y_axis} (Filtered)\")\n",
    "            st.plotly_chart(fig)\n",
    "        else:\n",
    "            st.warning(\"Need at least 1 numeric column for box plot\")\n",
    "    \n",
    "    elif viz_type == \"Violin Plot\":\n",
    "        if len(numeric_cols) >= 1:\n",
    "            y_axis = st.selectbox(\"Y-axis (numeric):\", numeric_cols)\n",
    "            x_axis = st.selectbox(\"X-axis (optional - categorical):\", [None] + list(cat_cols))\n",
    "            \n",
    "            fig = px.violin(filtered_df, x=x_axis, y=y_axis, \n",
    "                            title=f\"Violin Plot of {y_axis} (Filtered)\")\n",
    "            st.plotly_chart(fig)\n",
    "        else:\n",
    "            st.warning(\"Need at least 1 numeric column for violin plot\")\n",
    "    \n",
    "    elif viz_type == \"Pie Chart\":\n",
    "        if len(cat_cols) >= 1:\n",
    "            col = st.selectbox(\"Select categorical column:\", cat_cols)\n",
    "            \n",
    "            fig = px.pie(filtered_df, names=col, \n",
    "                         title=f\"Distribution of {col} (Filtered)\")\n",
    "            st.plotly_chart(fig)\n",
    "        else:\n",
    "            st.warning(\"Need at least 1 categorical column for pie chart\")\n",
    "    \n",
    "    elif viz_type == \"Heatmap\":\n",
    "        if len(numeric_cols) >= 2:\n",
    "            cols = st.multiselect(\"Select numeric columns:\", numeric_cols, default=numeric_cols[:5])\n",
    "            if len(cols) >= 2:\n",
    "                corr = filtered_df[cols].corr()\n",
    "                fig = px.imshow(corr, text_auto=True, \n",
    "                               title=\"Correlation Heatmap (Filtered)\")\n",
    "                st.plotly_chart(fig)\n",
    "            else:\n",
    "                st.warning(\"Need at least 2 numeric columns for heatmap\")\n",
    "        else:\n",
    "            st.warning(\"Need at least 2 numeric columns for heatmap\")\n",
    "    \n",
    "    elif viz_type == \"Pair Plot\":\n",
    "        if len(numeric_cols) >= 2:\n",
    "            cols = st.multiselect(\"Select numeric columns:\", numeric_cols, default=numeric_cols[:5])\n",
    "            hue = st.selectbox(\"Hue (optional - categorical):\", [None] + list(cat_cols))\n",
    "            \n",
    "            if len(cols) >= 2:\n",
    "                fig = px.scatter_matrix(filtered_df, dimensions=cols, color=hue,\n",
    "                                      title=\"Pair Plot (Filtered)\")\n",
    "                st.plotly_chart(fig)\n",
    "            else:\n",
    "                st.warning(\"Need at least 2 numeric columns for pair plot\")\n",
    "        else:\n",
    "            st.warning(\"Need at least 2 numeric columns for pair plot\")\n",
    "    \n",
    "    # Show filter summary\n",
    "    st.subheader(\"Filter Summary\")\n",
    "    st.write(f\"Original data points: {len(df)}\")\n",
    "    st.write(f\"Filtered data points: {len(filtered_df)}\")\n",
    "    st.write(f\"Percentage of data shown: {len(filtered_df)/len(df)*100:.1f}%\")\n",
    "    \n",
    "    if len(filtered_df) < len(df):\n",
    "        st.download_button(\n",
    "            label=\"Download Filtered Data\",\n",
    "            data=filtered_df.to_csv(index=False).encode('utf-8'),\n",
    "            file_name=\"filtered_data.csv\",\n",
    "            mime=\"text/csv\"\n",
    "        )\n",
    "\n",
    "# Step 5: Prediction\n",
    "elif options == \"Prediction\" and st.session_state.cleaned_df is not None:\n",
    "    st.header(\"Predictive Modeling\")\n",
    "    df = st.session_state.cleaned_df\n",
    "    \n",
    "    st.subheader(\"Select Target Variable\")\n",
    "    target = st.selectbox(\"Choose the target variable for prediction:\", df.columns)\n",
    "    st.session_state.target = target\n",
    "    \n",
    "    # Determine problem type\n",
    "    if df[target].dtype in ['int64', 'float64']:\n",
    "        unique_values = df[target].nunique()\n",
    "        if unique_values < 10:  # Arbitrary threshold for classification\n",
    "            problem_type = \"classification\"\n",
    "        else:\n",
    "            problem_type = \"regression\"\n",
    "    else:\n",
    "        problem_type = \"classification\"\n",
    "    \n",
    "    st.session_state.model_type = problem_type\n",
    "    st.write(f\"Automatically detected problem type: **{problem_type}**\")\n",
    "    \n",
    "    if st.button(\"Train Predictive Model\"):\n",
    "        with st.spinner(\"Training model...\"):\n",
    "            try:\n",
    "                # Prepare data\n",
    "                X = df.drop(columns=[target])\n",
    "                y = df[target]\n",
    "                \n",
    "                # Handle categorical features\n",
    "                cat_cols = X.select_dtypes(include=['object']).columns\n",
    "                for col in cat_cols:\n",
    "                    le = LabelEncoder()\n",
    "                    X[col] = le.fit_transform(X[col].astype(str))\n",
    "                \n",
    "                # Handle missing values (just in case)\n",
    "                imputer = SimpleImputer(strategy='mean')\n",
    "                X = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "                \n",
    "                # Split data\n",
    "                X_train, X_test, y_train, y_test = train_test_split(\n",
    "                    X, y, test_size=0.2, random_state=42\n",
    "                )\n",
    "                \n",
    "                # Scale features\n",
    "                scaler = StandardScaler()\n",
    "                X_train = scaler.fit_transform(X_train)\n",
    "                X_test = scaler.transform(X_test)\n",
    "                \n",
    "                # Train model\n",
    "                if problem_type == \"regression\":\n",
    "                    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "                    model.fit(X_train, y_train)\n",
    "                    y_pred = model.predict(X_test)\n",
    "                    score = model.score(X_test, y_test)\n",
    "                    mse = mean_squared_error(y_test, y_pred)\n",
    "                    st.success(f\"Regression Model Trained! R² Score: {score:.2f}, MSE: {mse:.2f}\")\n",
    "                else:\n",
    "                    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "                    model.fit(X_train, y_train)\n",
    "                    y_pred = model.predict(X_test)\n",
    "                    accuracy = accuracy_score(y_test, y_pred)\n",
    "                    st.success(f\"Classification Model Trained! Accuracy: {accuracy:.2f}\")\n",
    "                \n",
    "                st.session_state.model = model\n",
    "                \n",
    "                # Feature importance\n",
    "                st.subheader(\"Feature Importance\")\n",
    "                if problem_type == \"regression\":\n",
    "                    importance = model.feature_importances_\n",
    "                else:\n",
    "                    importance = model.feature_importances_\n",
    "                \n",
    "                feat_imp = pd.DataFrame({\n",
    "                    'Feature': X.columns,\n",
    "                    'Importance': importance\n",
    "                }).sort_values('Importance', ascending=False)\n",
    "                \n",
    "                fig, ax = plt.subplots(figsize=(10, 6))\n",
    "                sns.barplot(x='Importance', y='Feature', data=feat_imp, ax=ax)\n",
    "                ax.set_title('Feature Importance')\n",
    "                st.pyplot(fig)\n",
    "                \n",
    "            except Exception as e:\n",
    "                st.error(f\"Error training model: {e}\")\n",
    "\n",
    "elif options == \"Prediction\" and st.session_state.cleaned_df is None:\n",
    "    st.warning(\"Please clean your data first in the 'Data Cleaning' section.\")\n",
    "\n",
    "# Step 6: Insights\n",
    "elif options == \"Insights\" and st.session_state.cleaned_df is not None:\n",
    "    st.header(\"Data Storytelling & Insights\")\n",
    "    df = st.session_state.cleaned_df\n",
    "    \n",
    "    st.subheader(\"Key Insights from Your Data\")\n",
    "    \n",
    "    # Generate basic insights\n",
    "    numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "    cat_cols = df.select_dtypes(include=['object']).columns\n",
    "    \n",
    "    st.write(\"### Dataset Overview\")\n",
    "    st.write(f\"- The dataset contains **{df.shape[0]} rows** and **{df.shape[1]} columns**.\")\n",
    "    \n",
    "    if len(numeric_cols) > 0:\n",
    "        st.write(\"### Numeric Features Insights\")\n",
    "        for col in numeric_cols:\n",
    "            st.write(f\"- **{col}**:\")\n",
    "            st.write(f\"  - Range: {df[col].min():.2f} to {df[col].max():.2f}\")\n",
    "            st.write(f\"  - Average: {df[col].mean():.2f}\")\n",
    "            st.write(f\"  - Median: {df[col].median():.2f}\")\n",
    "            st.write(f\"  - Standard Deviation: {df[col].std():.2f}\")\n",
    "    \n",
    "    if len(cat_cols) > 0:\n",
    "        st.write(\"### Categorical Features Insights\")\n",
    "        for col in cat_cols:\n",
    "            st.write(f\"- **{col}**:\")\n",
    "            top_values = df[col].value_counts().head(3)\n",
    "            for val, count in top_values.items():\n",
    "                st.write(f\"  - '{val}' appears {count} times ({count/len(df)*100:.1f}%)\")\n",
    "    \n",
    "    # Correlation insights if available\n",
    "    if len(numeric_cols) >= 2:\n",
    "        st.write(\"### Correlation Insights\")\n",
    "        corr = df[numeric_cols].corr().unstack().sort_values(ascending=False)\n",
    "        corr = corr[corr != 1].drop_duplicates()\n",
    "        \n",
    "        top_pos = corr.nlargest(1)\n",
    "        top_neg = corr.nsmallest(1)\n",
    "        \n",
    "        for (col1, col2), val in top_pos.items():\n",
    "            st.write(f\"- The strongest positive correlation is between **{col1}** and **{col2}** (r = {val:.2f})\")\n",
    "        \n",
    "        for (col1, col2), val in top_neg.items():\n",
    "            st.write(f\"- The strongest negative correlation is between **{col1}** and **{col2}** (r = {val:.2f})\")\n",
    "    \n",
    "    # Prediction insights if available\n",
    "    if st.session_state.model is not None:\n",
    "        st.write(\"### Predictive Modeling Insights\")\n",
    "        target = st.session_state.target\n",
    "        model_type = st.session_state.model_type\n",
    "        \n",
    "        if model_type == \"regression\":\n",
    "            st.write(f\"- The model predicts **{target}** with reasonable accuracy.\")\n",
    "            st.write(\"- Features that most influence the prediction:\")\n",
    "            # Get feature importance (already calculated in prediction step)\n",
    "        else:\n",
    "            st.write(f\"- The model classifies **{target}** with reasonable accuracy.\")\n",
    "            st.write(\"- Features that most influence the classification:\")\n",
    "        \n",
    "        # Show top 3 features\n",
    "        X = df.drop(columns=[target])\n",
    "        if len(cat_cols) > 0:\n",
    "            for col in cat_cols:\n",
    "                le = LabelEncoder()\n",
    "                X[col] = le.fit_transform(X[col].astype(str))\n",
    "        \n",
    "        imputer = SimpleImputer(strategy='mean')\n",
    "        X = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "        \n",
    "        if st.session_state.model_type == \"regression\":\n",
    "            importance = st.session_state.model.feature_importances_\n",
    "        else:\n",
    "            importance = st.session_state.model.feature_importances_\n",
    "        \n",
    "        feat_imp = pd.DataFrame({\n",
    "            'Feature': X.columns,\n",
    "            'Importance': importance\n",
    "        }).sort_values('Importance', ascending=False).head(3)\n",
    "        \n",
    "        for _, row in feat_imp.iterrows():\n",
    "            st.write(f\"  - **{row['Feature']}** (importance: {row['Importance']:.3f})\")\n",
    "    \n",
    "    st.write(\"### Recommendations\")\n",
    "    st.write(\"- Based on the analysis, consider the following actions:\")\n",
    "    st.write(\"  1. Investigate the strongest correlations for potential causal relationships\")\n",
    "    st.write(\"  2. Explore the most important features identified by the predictive model\")\n",
    "    if len(numeric_cols) > 0:\n",
    "        st.write(\"  3. Examine outliers in numeric features that may need special handling\")\n",
    "    if len(cat_cols) > 0:\n",
    "        st.write(\"  4. Analyze the distribution of categorical variables for imbalances\")\n",
    "    \n",
    "    st.write(\"### Next Steps\")\n",
    "    st.write(\"- To dive deeper into the analysis:\")\n",
    "    st.write(\"  1. Export the cleaned dataset for further analysis\")\n",
    "    st.write(\"  2. Try different visualization types to uncover hidden patterns\")\n",
    "    st.write(\"  3. Experiment with different predictive models and parameters\")\n",
    "\n",
    "elif options == \"Insights\" and st.session_state.cleaned_df is None:\n",
    "    st.warning(\"Please clean your data first in the 'Data Cleaning' section.\")\n",
    "\n",
    "# Footer\n",
    "st.sidebar.markdown(\"---\")\n",
    "st.sidebar.markdown(\"\"\"\n",
    "**Data Solution**  \n",
    "Created with Streamlit, Pandas, and Scikit-learn    \n",
    "\"\"\")\n",
    "\n",
    "# Add export/download buttons\n",
    "if st.session_state.cleaned_df is not None:\n",
    "    st.sidebar.markdown(\"---\")\n",
    "    st.sidebar.subheader(\"Export Data\")\n",
    "    \n",
    "    # Export cleaned data\n",
    "    csv = st.session_state.cleaned_df.to_csv(index=False).encode('utf-8')\n",
    "    st.sidebar.download_button(\n",
    "        label=\"Download Cleaned Data (CSV)\",\n",
    "        data=csv,\n",
    "        file_name=\"cleaned_data.csv\",\n",
    "        mime=\"text/csv\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
